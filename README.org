* Abstract

hunchentoot-recycling-taskmaster is a hunchentoot taskmaster implementation
that aims to improve the efficiency of connection establishment by
adding a thread recycling mechanism.
This mechanism is implemented by using the listen socket itself for
thread synchronization.
Therefore, it successfully implements a thread-pool-like mechanism
without adding any new dependent libraries to hunchentoot.

* TODO performance tl;dr

[Image *no keep-alive* *sleeps for 1ms*.]
[Image *keep-alive* *sleeps for 1ms*.]

On this benchmark, my HTTP handler *always sleeps for 1ms* to simulate some workloads.

- Hunchentoot is an all-rounder. It works well on Keep-alive connections. I think it is good for typical use-cases.
- If your workload does not utilize Keep-alive, my hunchentoot-recycling-taskmaster may be useful.
- Woo is very difficult to use. Woo seems fast only when your handlers works with strictly no latency. See below [link to "About Woo" below.]

* How to use

** About Lispworks

On Lispworks, hunchentoot-recycling-taskmaster does not works because
Hunchentoot on that does not handle a listen socket directly.

** Installation

*** Loading

Currently hunchentoot-recycling-taskmaster is not on Quicklisp or ocicl.
Please download it by yourself.

#+begin_src sh
  cd ~/quicklisp/local-projects
  git clone https://github.com/y2q-actionman/hunchentoot-recycling-taskmaster.git
#+end_src

#+begin_src lisp
  (ql:register-local-projects)            ; Do if required
  (ql:quickload "hunchentoot-recycling-taskmaster")
#+end_src

*** Running tests

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-test")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster)
#+end_src

** Starting/stopping server

You can use hunchentoot-recycling-taskmaster just by changing
=hunchentoot:acceptor= to =hunchentoot-recycling-taskmaster:parallel-acceptor=, or
=hunchentoot:easy-acceptor= to =hunchentoot-recycling-taskmaster:parallel-easy-acceptor=.

#+begin_src common-lisp
  (defparameter *test-server*
    (make-instance 'hunchentoot-recycling-taskmaster:parallel-easy-acceptor
		   :port 4242))
  (hunchentoot:start *test-server*)
#+end_src

#+begin_src bash
  curl "http://127.0.0.1:4242/yo"
  # => "Hey!"
#+end_src

For stopping, =hunchentoot:stop= can be used.

#+begin_src common-lisp
  (hunchentoot:stop *test-server*)
#+end_src

See [[file:demo.lisp][demo.lisp]] for examples above.

* How it works

#+ATTR_ORG: :width 300
[[file:pics/hunchentoot-architecture.dot.png]]

(stub hunchentoot)

#+ATTR_ORG: :width 300
[[file:pics/hunchentoot-thread-pooling.dot.png]]

(stub hunchentoot + thread-pooling)

#+ATTR_ORG: :width 300
[[file:pics/hunchentoot-recycling-taskmaster-architecture.dot.png]]

(stub hunchentoot-recycling-taskmaster;  thread-pooling + variable number of threads.)

* Benchmarking

** Running benchmarks

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-benchmark")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster-benchmark)
#+end_src

** no keep-alive, sleep 0.1ms

[Image]

** keep-alive, sleep 0.1ms

[Image]

Hunchentoot は接続ごとに 1 thread を割り当てる。

これはつまり、 HTTP/1.1 の keep-alive が有効であれば、 "Connection: close" などで明示的に接続を
閉じるまでは、その接続に対応する thread はずっと使い回されることを意味する。

そのため、 keep-alive が有効に使われている workload ならそんなに遅くない。
wrk は keep-alive を default で使用するので、この恩恵を受けている。

** keep-alive, no sleep

[Image]

Woo はこの場合だけは早い。

*** About Woo

Woo は handler が少しでも遅延すると disastaours に遅くなる。
上の "0.1ms sleep" のとき、  Woo の handler には以下のように書いたが、これが酷い結果を招く。

#+begin_src lisp
  (lambda (env)
    (declare (ignore env))
    (sleep 0.0001)
    '(200 (:content-type "text/plain") ("Hello, World")))
#+end_src

これは、 Woo が 1 thread で複数の connection を同時に扱う async なサーバであるため、
 1 connection の処理の中で遅延が発生すると同一 thread の他 connection 全ての処理が遅延するためである。
async な architecture から考えれば sleep してはいけないのは自明のことだ。

さてこのような場合、一般的には async server の event loop 内部で sleep したりはしない。
event loop の外で時間がかかる処理を実行し、それが終わったら event loop に送受信する内容を通知したり、
callback を呼び出してもらうよう設定したりするようなことが行われる。
(このため、かつて =async= が使われるようになるより前の Node.js の code は callback hell などと呼ばれていたわけだが)


しかし、どういうわけか Woo にはそのような仕組みがないように思う。私は見つけられなかった。
Woo を使っているとされる quickdocks-api や、 https://github.com/TechEmpower/FrameworkBenchmarks/pull/8313 では
そのような配慮はしていないようだ。
(だから https://www.reddit.com/r/Common_Lisp/comments/1506kqb/comment/js220a6/ の link 先で見られる benchmark 結果は奮わないのだろう。)

一部 SNS のコメント ( https://lisp-journey.gitlab.io/blog/why-turtl-switched-from-lisp-to-js/,
reddit のやつ) では、 "lparallel で offload できる" と言っている人がいるが、それを実際にやっている
コードを私はまだ見付けられていない。以下のような naive に thread を立てるコードはエラーになる。
event loop の実体であるところの =*evloop*= 変数は =(make-thread)= で作った thread では
参照できず、 =NIL= になってしまうためだ。

この問題は Woo が依存している libev を直接扱い、 event loop を直接扱って、 sleep 等を
自分で作れば解決できなくはない。 [このコード] は Gemini-CLI が書いてきたものである。
確かに動作したし benchmark も悪くない。ただ、このコードがどうやって動いているかを私は知らない。
聞かないでほしい。


そういうわけで、 Woo で "sleep 0.1ms" を benchmark するのには、上記の酷いコード例
を使わざるを得ないように思う。これは Woo にとって非常に不利だが、 Woo のサポートが
欠如しているので仕方のないことだろう。

Woo の状況が変わらなければ、 it could be said that Woo is very fast only when your handlers does not compute anything.
 think Woo is *only* good for serving static pages.
   # but why did such a thing by Lisp? Use nginx.

* Ideas

bordeaux-threads-2 に追加された atomic 変数を使って lock を減らすのも試してみた。

SBCL においては、 hunchentoot の slot については効果が少なかった。
recycling-taskmaster の追加 slot においては有効であった。

[Image]

Allegro CL においては、結構ききめがあった。
おそらくは lock の競合がとても重いせいかなと思う。

[Image]

* License

BSD 2-Clause, same as Hunchentoot. See [[file:LICENSE][LICENSE]].
