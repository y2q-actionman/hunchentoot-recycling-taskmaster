* Abstract

hunchentoot-recycling-taskmaster is a taskmaster implementation for Hunchentoot,
aiming to improve connection establishment efficiency through thread-pooling
and flexible thread count adjustment.

* Performance tl;dr

[[file:pics/benchmark-result-2025-12-26/sleep_1ms/keep-alive/100_connections_requests_sec__sleep_1ms__keep-alive__higher_is_better.svg]]

[[file:pics/benchmark-result-2025-12-26/sleep_1ms/no-keep-alive/100_connections_requests_sec__sleep_1ms__no_keep-alive__higher_is_better.svg]]

On this benchmark, my HTTP handler *always responds after 1ms* to simulate some workloads.

- Hunchentoot is an all-rounder. It works well on Keep-alive connections. I think it is good for typical use-cases.
- If your workload does not utilize Keep-alive, hunchentoot-recycling-taskmaster may be useful.
- Woo is very difficult to use. Woo seems fast only when your handlers work with strictly no latency. See [[#about-woo][About Woo]] below.

In detail, See [[#benchmark][Benchmark]] below.
  
* How to use

** Caution about Lispworks

On Lispworks, hunchentoot-recycling-taskmaster does not works because
Hunchentoot on that does not handle a listen socket directly.

** Installation

*** Loading

Currently hunchentoot-recycling-taskmaster is not on Quicklisp, Ultralisp or ocicl.
Please download it by yourself.

#+begin_src sh
  cd ~/quicklisp/local-projects
  git clone https://github.com/y2q-actionman/hunchentoot-recycling-taskmaster.git
#+end_src

#+begin_src lisp
  (ql:register-local-projects)            ; Do if required
  (ql:quickload "hunchentoot-recycling-taskmaster")
#+end_src

*** Running tests

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-test")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster)
#+end_src

** Starting/stopping server

You can use hunchentoot-recycling-taskmaster just by changing
=hunchentoot:acceptor= to =hunchentoot-recycling-taskmaster:parallel-acceptor=, or
=hunchentoot:easy-acceptor= to =hunchentoot-recycling-taskmaster:parallel-easy-acceptor=.

#+begin_src common-lisp
  (defparameter *test-server*
    (make-instance 'hunchentoot-recycling-taskmaster:parallel-easy-acceptor
		   :port 4242))
  (hunchentoot:start *test-server*)
#+end_src

#+begin_src bash
  curl "http://127.0.0.1:4242/yo"
  # => "Hey!"
#+end_src

To stop it, =hunchentoot:stop= can be used.

#+begin_src common-lisp
  (hunchentoot:stop *test-server*)
#+end_src

See [[file:demo.lisp][demo.lisp]] for the sample codes above.

** API

These symbols are exported from =hunchentoot-recycling-taskmaster= package.
Please see their docstring also.

- [Class] =parallel-acceptor=
- [Class] =parallel-easy-acceptor=
- [Class] =parallel-ssl-acceptor=
- [Class] =parallel-easy-ssl-acceptor=
- [Class] =recycling-taskmaster=
- [Variable] =*default-standby-thread-count*=
  
- [Function] =abandon-acceptor=
- [Condition] =recycling-taskmaster-corrupted-error=

* How it works

hunchentoot-recycling-taskmaster is a hunchentoot taskmaster
implementation that aims to improve the efficiency of connection
establishment. This section shows how it works.

** Hunchentoot; make one thread per connection.

[[file:pics/architecture/hunchentoot-architecture.dot.png]]

Hunchentoot uses one thread per one connection.  It means when a
client use one keep-alive connection for multiple requests,
Hunchentoot dedicate one thread to that connection.  There is some
delay for new connections, but it works well on keep-alive
connections.

** quux-hunchentoot and cl-tbnl-gserver-tmgr; Thread pooling

[[file:pics/architecture/hunchentoot-thread-pooling.dot.png]]

These implementations utilize a thread pool around Hunchentoot.
Instead of making a new thread for a new connection, they reuse
threads kept in its thread pool, reducing latency for new connections.

However, their benchmarks don't show significant differences from the
original Hunchentoot. I suspect this is for two reasons:

1. HTTP benchmarking tool, such as "wrk", utilizes keep-alive
   connections.  Effects of thread-pooling are limited at the
   beginning of benchmarking.
2. Their thread-pool's size may be fixed. They cannot
   increase threads like Hunchentoot even on high workloads.

** hunchentoot-recycling-taskmaster

[[file:pics/architecture/hunchentoot-recycling-taskmaster-architecture.dot.png]]

hunchentoot-recycling-taskmaster tries to take both, thread-pooling
and changing the number of threads dynamically. In
hunchentoot-recycling-taskmaster, threads don't only work on connected
sockets but also some management tasks, such as accepting a new
connection from the listen socket, creating a new thread, or
terminating themselves.

For this management, all threads share the listen socket for
synchronizing acceptance and track how many threads on it.  Since
using the listen socket, hunchentoot-recycling-taskmaster successfully
implements these mechanisms without adding new dependencies to
hunchentoot.

* Benchmark

** Running benchmarks
To run benchmark by yourself, do below:

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-benchmark")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster-benchmark)
#+end_src

** My Environments

*** My machine

| cl function name            |                                     |
|-----------------------------+-------------------------------------|
| LISP-IMPLEMENTATION-TYPE    | SBCL                                |
| LISP-IMPLEMENTATION-VERSION | 2.2.9.debian                        |
| MACHINE-TYPE                | X86-64                              |
| MACHINE-VERSION             | 13th Gen Intel(R) Core(TM) i7-1360P |
| SOFTWARE-TYPE               | Linux                               |
| SOFTWARE-VERSION            | 5.15.153.1-microsoft-standard-WSL2  |

*** Server library versions and parameters

| name                             | parameters             | version | Git commit                               |
|----------------------------------+------------------------+---------+------------------------------------------|
| hunchentoot-recycling-taskmaster | standby-thread-count 8 |   0.0.1 | 82913edaf3f65afb189f0d72ddeb6339bf0499ae |
| hunchentoot                      |                        |   1.3.1 | d1617e9d4eab6cb801c56cf36d9b0aab134fb7e6 |
| quux-hunchentoot                 |                        |   1.0.2 | quux-hunchentoot-20211230-git            |
| cl-tbnl-gserver-tmgr             | max-thread-count 8     |   0.1.1 | 1ae71c9324e876761cd1ee51768a34f0793e6879 |
| wookie                           |                        |  0.3.15 | 1f74b6c24b463c1e6fff35377e477934f72bac20 |
| woo                              | worker-num 8           |  0.12.0 | 7f5219c55d49190f5ae17b123a8729b31c5d706e |

*** benchmarking tool

I used *wrk*, like below

#+begin_src bash
  # keep-alive
  wrk -t 4 -c 100 -d 10 http://localhost:4242/yo
  # simulating no keep-alive
  wrk "-H Connection: close" -t 4 -c 100 -d 10 http://localhost:4242/yo
#+end_src

** Results

*** keep-alive, sleep 1ms

[[file:pics/benchmark-result-2025-12-26/sleep_1ms/keep-alive/100_connections_requests_sec__sleep_1ms__keep-alive__higher_is_better.svg]]
[[file:pics/benchmark-result-2025-12-26/sleep_1ms/keep-alive/100_connections_latency(us)__sleep_1ms__keep-alive__lower_is_better.svg]]

On this benchmark, my HTTP handler *always responds after 1ms* to simulate some workloads.

Hunchentoot is quite fast.  As mentioned above, Hunchentoot assigns
one thread per connection and keeps using that thread until the
connection is closed.  Therefore, if a connection is kept alive,
there's no delay from thread creation, and it doesn't become
Hunchentoot slow.  =wrk= uses keep-alive by default, so this result
benefits from this.

cl-tbnl-gserver-tmgr is not very fast. This is presumably because it
only assigns 8 threads as workers.

Woo is not fast even set to 8 threads. See [[#about-woo][About Woo]] below.

*** no keep-alive, sleep 1ms

[[file:pics/benchmark-result-2025-12-26/sleep_1ms/no-keep-alive/100_connections_requests_sec__sleep_1ms__no_keep-alive__higher_is_better.svg]]
[[file:pics/benchmark-result-2025-12-26/sleep_1ms/no-keep-alive/100_connections_latency(us)__sleep_1ms__no_keep-alive__lower_is_better.svg]]

On this benchmark, HTTP handler still causes 1ms latency, and I
simulated "no keep-alive" by adding =wrk= option ="-H Connection:
close"= .

Hunchentoot became quite slow. In this test, Hunchentoot works like
"one thread per one request" so latencies caused by creating a new
thread affected the result.

hunchentoot-recycling-taskmaster is designed to work well in this
situation.

*** keep-alive, sleep 0ms

[[file:pics/benchmark-result-2025-12-26/sleep_0ms/keep-alive/100_connections_requests_sec__sleep_0ms__keep-alive__higher_is_better.svg]]
[[file:pics/benchmark-result-2025-12-26/sleep_0ms/keep-alive/100_connections_latency(us)__sleep_0ms__keep-alive__lower_is_better.svg]]

On this benchmark, I set HTTP handler's latency to 0ms. (However some
latencies caused by small computations still exist. See [[#about-woo][About Woo]] below.)

hunchentoot-recycling-taskmaster became fast. I think this is because
threads are accepting connections in parallel.

*** no keep-alive, sleep 0ms

[[file:pics/benchmark-result-2025-12-26/sleep_0ms/no-keep-alive/100_connections_requests_sec__sleep_0ms__no_keep-alive__higher_is_better.svg]]
[[file:pics/benchmark-result-2025-12-26/sleep_0ms/no-keep-alive/100_connections_latency(us)__sleep_0ms__no_keep-alive__lower_is_better.svg]]

On this benchmark, I set HTTP handler's latency to 0ms like above, and set
=wrk= option ="-H Connection:close"= .

Here, Woo finally takes first place, with
hunchentoot-recycling-taskmaster coming in a close second.

*** Other results

- See [[pics/benchmark-result-2025-12-26/benchmark-result-2025-12-26.org][benchmark-result-2025-12-26.org]] for graphs with "400 connections" parameters
- See [[benchmark/benchmark-result-2025-12-26][this directory]] for raw data.

** About Woo

Woo は handler が少しでも遅延すると disastaours に遅くなる。
上の "1ms sleep" のとき、  Woo は以下のように起動しているが、これが酷い結果を招く。

#+begin_src lisp
  (defparameter *handler-sleep-seconds* 0)

  (defun handler-small-sleep ()
    (sleep *handler-sleep-seconds*))

  (woo:run
   (lambda (env)
     (declare (ignore env))
     (handler-small-sleep)
     '(200 (:content-type "text/plain") ("Hello, World")))
   :worker-num 8)
#+end_src

これは、 Woo が 1 thread で複数の connection を同時に扱う async なサーバであるため、
 1 connection の処理の中で遅延が発生すると同一 thread の他 connection 全ての処理が遅延するためである。
async な architecture から考えれば sleep してはいけないのは自明のことだ。

さてこのような場合、一般的には async server の event loop 内部で sleep したりはしない。
event loop の外で時間がかかる処理を実行し、それが終わったら event loop に送受信する内容を通知したり、
callback を呼び出してもらうよう設定したりするようなことが行われる。
(このため、かつて =async= が使われるようになるより前の Node.js の code は callback hell などと呼ばれていたわけだが)


しかし、どういうわけか Woo にはそのような仕組みがないように思う。私は見つけられなかった。
Woo を使っているとされる quickdocs-api や、 https://github.com/TechEmpower/FrameworkBenchmarks/pull/8313 では
そのような配慮はしていないようだ。
(だから https://www.reddit.com/r/Common_Lisp/comments/1506kqb/comment/js220a6/ の link 先で見られる benchmark 結果は奮わないのだろう。
https://www.reddit.com/r/Common_Lisp/comments/1hgbaco/how_fast_common_lisp_could_be_tremendous/)

一部 SNS のコメント ( https://lisp-journey.gitlab.io/blog/why-turtl-switched-from-lisp-to-js/,
reddit のやつ) では、 "lparallel で offload できる" と言っている人がいるが、それを実際にやっている
コードを私はまだ見付けられていない。以下のような naive に thread を立てるコードはエラーになる。
event loop の実体であるところの =*evloop*= 変数は =(make-thread)= で作った thread では
参照できず、 =NIL= になってしまうためだ。

(lparallelすればいいじゃん　→　最初からhunchentootでいいじゃん。それだと one-thread-per-request になり得る)

この問題は Woo が依存している libev を直接扱い、 event loop を直接扱って、 sleep 等を
自分で作れば解決できなくはない。 [このコード] は Gemini-CLI が書いてきたものである。
確かに動作したし benchmark も悪くない。ただ、このコードがどうやって動いているかを私は知らない。
聞かないでほしい。


そういうわけで、 Woo で "sleep 1ms" を benchmark するのには、上記の酷いコード例
を使わざるを得ないように思う。これは Woo にとって非常に不利だが、 Woo のサポートが
欠如がしているし、 quickdocs-api もそのように書かれているので仕方のないことだろう。


また、 "sleep 0ms" を見て「世間で言われているほど Woo が速くないのでは？」と思った人もいるだろう。
私もそう思って調べたところ、この benchmark の handler 定義を以下のようにしていることが原因と分かった。

#+begin_src common-lisp
  (defparameter *handler-sleep-seconds* 0)

  (defun handler-small-sleep ()
  (sleep *handler-sleep-seconds*))

  (woo:run
		  (lambda (env)
		    (declare (ignore env))
		    (handler-small-sleep)
		    '(200 (:content-type "text/plain") ("Hello, World")))
		  :worker-num threads)

#+end_src

このコードは以下を行う。
1. special varibale を eval する。 (0 になる)
2. =cl:sleep= を 0 で呼ぶ。 (直ちに戻る。

この二つの処理はほどんど時間がかかるものではないが、残念ながら woo では問題になる。
以下のように =handler-small-sleep= を変更すると、次の graph のように速くなったのである。

#+begin_src common-lisp
(defun handler-small-sleep ()
  #+ ()
  (sleep *handler-sleep-seconds*))
#+end_src

[[file:pics/benchmark-result-2025-12-26/sleep_0ms_no_special_vars/keep-alive/100_connections_requests_sec__sleep_commented_out__keep-alive__higher_is_better.svg]]
[[file:pics/benchmark-result-2025-12-26/sleep_0ms_no_special_vars/keep-alive/100_connections_latency(us)__sleep_commented_out__keep-alive__lower_is_better.svg]]

というわけで、 Woo の性能を引き出すには special variable も呼んではいけないことが分かる。
つまり、 Woo においては your handlers works with strictly no latency でないといけないのである。


Woo の状況が変わらなければ、 it could be said that Woo is very fast only when your handlers does not compute anything.
 think Woo is *only* good for serving static pages or microbenchmarking

# but why did such a thing by Lisp? Use nginx.



   

* TODO TODO list

** register to systems

- [ ] quicklisp
- [ ] ultralisp
- [ ] ocicl

** Benchmark other servers

- [ ] conserv :: Causing =cl:type-error= when I used its sample code.
- [ ] house :: Very fragile. See [[benchmark/about_house/about_house.org][my memo]] .
- [ ] teepeedee2 :: cannot be loaded by my machine because of [[benchmark/loading.org]["heap exhausted" error]].

** Ideas

- [ ] Using atomic variables -- its impact is small on SBCL, large on Allegro CL.
- [ ] make the  number of standby-thread-count to variadic.

* License

BSD 2-Clause, same as Hunchentoot. See [[file:LICENSE][LICENSE]].
