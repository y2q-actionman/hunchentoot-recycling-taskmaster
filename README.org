* Abstract

hunchentoot-recycling-taskmaster is a taskmaster implementation for Hunchentoot,
aiming to improve connection establishment efficiency through thread-pooling
and flexible thread count adjustment.

* Performance tl;dr

[[file:pics/benchmark-result-2025-12-26/sleep_1ms/no-keep-alive/100 connections requests_sec, sleep 1ms, no keep-alive, higher is better.svg]]
[[
file:pics/benchmark-result-2025-12-26/sleep_1ms/keep-alive/100 connections requests_sec, sleep 1ms, no keep-alive, higher is better.svg]]

On this benchmark, my HTTP handler *always responds after 1ms* to simulate some workloads.

- Hunchentoot is an all-rounder. It works well on Keep-alive connections. I think it is good for typical use-cases.
- If your workload does not utilize Keep-alive, hunchentoot-recycling-taskmaster may be useful.
- Woo is very difficult to use. Woo seems fast only when your handlers work with strictly no latency. See [[#about-woo][About Woo]] below.

In detail, See [[#benchmarking][Benchmarking]] below.
  
* How to use

** About Lispworks

On Lispworks, hunchentoot-recycling-taskmaster does not works because
Hunchentoot on that does not handle a listen socket directly.

** Installation

*** Loading

Currently hunchentoot-recycling-taskmaster is not on Quicklisp, Ultralisp or ocicl.
Please download it by yourself.

#+begin_src sh
  cd ~/quicklisp/local-projects
  git clone https://github.com/y2q-actionman/hunchentoot-recycling-taskmaster.git
#+end_src

#+begin_src lisp
  (ql:register-local-projects)            ; Do if required
  (ql:quickload "hunchentoot-recycling-taskmaster")
#+end_src

*** Running tests

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-test")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster)
#+end_src

** Starting/stopping server

You can use hunchentoot-recycling-taskmaster just by changing
=hunchentoot:acceptor= to =hunchentoot-recycling-taskmaster:parallel-acceptor=, or
=hunchentoot:easy-acceptor= to =hunchentoot-recycling-taskmaster:parallel-easy-acceptor=.

#+begin_src common-lisp
  (defparameter *test-server*
    (make-instance 'hunchentoot-recycling-taskmaster:parallel-easy-acceptor
		   :port 4242))
  (hunchentoot:start *test-server*)
#+end_src

#+begin_src bash
  curl "http://127.0.0.1:4242/yo"
  # => "Hey!"
#+end_src

To stop it, =hunchentoot:stop= can be used.

#+begin_src common-lisp
  (hunchentoot:stop *test-server*)
#+end_src

See [[file:demo.lisp][demo.lisp]] for the sample codes above.

** API

These symbols are exported from the `hunchentoot-recycling-taskmaster` package.
Please see their docstring also.

- [Class] =parallel-acceptor=
- [Class] =parallel-easy-acceptor=
- [Class] =parallel-ssl-acceptor=
- [Class] =parallel-easy-ssl-acceptor=
- [Class] =recycling-taskmaster=
- [Variable] =*default-standby-thread-count*=
  
- [Function] =abandon-acceptor=
- [Condition] =recycling-taskmaster-corrupted-error=

* How it works


hunchentoot-recycling-taskmaster is a hunchentoot taskmaster implementation
that aims to improve the efficiency of connection establishment by
adding a thread recycling mechanism.
This mechanism is implemented by using the listen socket itself for
thread synchronization.
Therefore, it successfully implements a thread-pool-like mechanism
without adding any new dependent libraries to hunchentoot.

** Hunchentoot; make one thread per connection.

[[file:pics/hunchentoot-architecture.dot.png]]

Hunchentoot makes one thread per one connection.
It delays a bit for every new connections, but
it runs well on keep-alive connections.

** quux-hunchentoot and cl-tbnl-gserver-tmgr; Thread pooling

[[file:pics/hunchentoot-thread-pooling.dot.png]]

These implementations utilize a thread pool around Hunchentoot.
Instead of making a new thread for a new connection, they
reuse threads kept in its thread pool, so
they can reduce latency for new connections.

However, their benchmarks don't show signifinant differences
from the original Hunchentoot. This is because of two reasons.

1. HTTP benchmarking tool like "wrk" utilizes keep-alive connections.
   Effects of thread-pooling is limited at the beginning.
2. Their thread-pool's size may be fixed. They cannot
   increase threads like Hunchentoot even on high workloads.

** hunchentoot-recycling-taskmaster

[[file:pics/hunchentoot-recycling-taskmaster-architecture.dot.png]]



(stub hunchentoot-recycling-taskmaster;  thread-pooling + variable number of threads.)

* Benchmarking

** Running benchmarks

#+begin_src common-lisp
  (ql:quickload "hunchentoot-recycling-taskmaster-benchmark")
  (asdf:test-system '#:hunchentoot-recycling-taskmaster-benchmark)
#+end_src

** no keep-alive, sleep 0.1ms

[Image]

** keep-alive, sleep 0.1ms

[Image]

Hunchentoot は接続ごとに 1 thread を割り当てる。

これはつまり、 HTTP/1.1 の keep-alive が有効であれば、 "Connection: close" などで明示的に接続を
閉じるまでは、その接続に対応する thread はずっと使い回されることを意味する。

そのため、 keep-alive が有効に使われている workload ならそんなに遅くない。
wrk は keep-alive を default で使用するので、この恩恵を受けている。

** keep-alive, no sleep

[Image]

Woo はこの場合だけは早い。

*** About Woo

Woo は handler が少しでも遅延すると disastaours に遅くなる。
上の "0.1ms sleep" のとき、  Woo の handler には以下のように書いたが、これが酷い結果を招く。

#+begin_src lisp
  (lambda (env)
    (declare (ignore env))
    (sleep 0.0001)
    '(200 (:content-type "text/plain") ("Hello, World")))
#+end_src

これは、 Woo が 1 thread で複数の connection を同時に扱う async なサーバであるため、
 1 connection の処理の中で遅延が発生すると同一 thread の他 connection 全ての処理が遅延するためである。
async な architecture から考えれば sleep してはいけないのは自明のことだ。

さてこのような場合、一般的には async server の event loop 内部で sleep したりはしない。
event loop の外で時間がかかる処理を実行し、それが終わったら event loop に送受信する内容を通知したり、
callback を呼び出してもらうよう設定したりするようなことが行われる。
(このため、かつて =async= が使われるようになるより前の Node.js の code は callback hell などと呼ばれていたわけだが)


しかし、どういうわけか Woo にはそのような仕組みがないように思う。私は見つけられなかった。
Woo を使っているとされる quickdocs-api や、 https://github.com/TechEmpower/FrameworkBenchmarks/pull/8313 では
そのような配慮はしていないようだ。
(だから https://www.reddit.com/r/Common_Lisp/comments/1506kqb/comment/js220a6/ の link 先で見られる benchmark 結果は奮わないのだろう。
https://www.reddit.com/r/Common_Lisp/comments/1hgbaco/how_fast_common_lisp_could_be_tremendous/)

一部 SNS のコメント ( https://lisp-journey.gitlab.io/blog/why-turtl-switched-from-lisp-to-js/,
reddit のやつ) では、 "lparallel で offload できる" と言っている人がいるが、それを実際にやっている
コードを私はまだ見付けられていない。以下のような naive に thread を立てるコードはエラーになる。
event loop の実体であるところの =*evloop*= 変数は =(make-thread)= で作った thread では
参照できず、 =NIL= になってしまうためだ。

(lparallelすればいいじゃん　→　最初からhunchentootでいいじゃん。それだと one-thread-per-request になり得る)

この問題は Woo が依存している libev を直接扱い、 event loop を直接扱って、 sleep 等を
自分で作れば解決できなくはない。 [このコード] は Gemini-CLI が書いてきたものである。
確かに動作したし benchmark も悪くない。ただ、このコードがどうやって動いているかを私は知らない。
聞かないでほしい。


そういうわけで、 Woo で "sleep 1ms" を benchmark するのには、上記の酷いコード例
を使わざるを得ないように思う。これは Woo にとって非常に不利だが、 Woo のサポートが
欠如がしているし、 quickdocs-api もそのように書かれているので仕方のないことだろう。


また、 "sleep 0ms" を見て「世間で言われているほど Woo が速くないのでは？」と思った人もいるだろう。
私もそう思って調べたところ、この benchmark の handler 定義を以下のようにしていることが原因と分かった。

#+begin_src common-lisp
  (defparameter *handler-sleep-seconds* 0)

  (defun handler-small-sleep ()
  (sleep *handler-sleep-seconds*))

  (woo:run
		  (lambda (env)
		    (declare (ignore env))
		    (handler-small-sleep)
		    '(200 (:content-type "text/plain") ("Hello, World")))
		  :worker-num threads)

#+end_src

このコードは以下を行う。
1. special varibale を eval する。 (0 になる)
2. =cl:sleep= を 0 で呼ぶ。 (直ちに戻る。

この二つの処理はほどんど時間がかかるものではないが、残念ながら woo では問題になる。
以下のように =handler-small-sleep= を変更すると、次の graph のように速くなったのである。

#+begin_src common-lisp
(defun handler-small-sleep ()
  #+ ()
  (sleep *handler-sleep-seconds*))
#+end_src

[Graph]

というわけで、 Woo の性能を引き出すには special variable も呼んではいけないことが分かる。
つまり、 Woo においては your handlers works with strictly no latency でないといけないのである。


Woo の状況が変わらなければ、 it could be said that Woo is very fast only when your handlers does not compute anything.
 think Woo is *only* good for serving static pages or microbenchmarking

# but why did such a thing by Lisp? Use nginx.



   
*** About House

House is very fragile.

With my few patch (https://github.com/y2q-actionman/house), I tried it using =curl=.
It works at first:

#+begin_quote
CL-USER> (use-package :house)
T
CL-USER> (define-handler (hello-world :content-type "text/plain") ()
      "Hello world!")
	(define-handler (hello-you/<name>=>>string) ()
	  (format nil "Hello there, ~a!" name))
	(house:start 4040)
#+end_quote

#+begin_quote
$ curl http://localhost:4040/hello-world
Hello world!
#+end_quote

However, it breaks when I used =wrk=:

#+begin_quote
$ wrk -t 4 -c 10 -d 10 http://localhost:4040/hello-world
Running 10s test @ http://localhost:4040/hello-world
  4 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   382.00us    0.00us 382.00us  100.00%
    Req/Sec    10.00      0.00    10.00    100.00%
  1 requests in 10.10s, 307.00B read
  Socket errors: connect 0, read 68057, write 0, timeout 0
Requests/sec:      0.10
Transfer/sec:      30.40B
#+end_quote

After that, =curl= fails also.

#+begin_quote
$ curl http://localhost:4040/hello-world
curl: (52) Empty reply from server
#+end_quote

So, I gave up to benchmaking house...


* TODO

quicklisp
ultralisp
ocicl

* Ideas

bordeaux-threads-2 に追加された atomic 変数を使って lock を減らすのも試してみた。

SBCL においては、 hunchentoot の slot については効果が少なかった。
recycling-taskmaster の追加 slot においては有効であった。

[Image]

Allegro CL においては、結構ききめがあった。
おそらくは lock の競合がとても重いせいかなと思う。

[Image]

* License

BSD 2-Clause, same as Hunchentoot. See [[file:LICENSE][LICENSE]].
